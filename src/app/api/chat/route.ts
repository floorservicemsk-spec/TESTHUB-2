import { NextRequest, NextResponse } from "next/server";
import { invokeLLM, AIProviderSettings } from "@/lib/llm";
import { withCache, aiSettingsCache, knowledgeBaseCache } from "@/lib/cache";
import { checkRateLimit } from "@/lib/rate-limiter";

// Define type locally to avoid build-time prisma import
type KnowledgeType = "DOCUMENT" | "LINK" | "YANDEX_DISK" | "XML_FEED";
import { aiQueue } from "@/lib/ai-queue";
import { aiResponseCache } from "@/lib/ai-cache";
import { analyzeQuestion, getInstantResponse } from "@/lib/smart-router";
import {
  extractArticleCode,
  isKnowledgeBaseRequest,
  getCachedArticleResponse,
  cacheArticleResponse,
} from "@/lib/article-service";

export const dynamic = "force-dynamic";

// Lazy prisma import to avoid build-time issues
const getPrisma = async () => {
  const { default: prisma } = await import("@/lib/prisma");
  return prisma;
};


interface ChatMessage {
  id: string;
  role: "user" | "assistant";
  content: string;
  timestamp: string;
  attachments?: Array<{ name: string; url: string; type: string }>;
}

interface Product {
  id: string;
  name: string;
  vendorCode: string;
  price: number | null;
  description: string;
  picture: string;
  params: Record<string, unknown>;
}

interface KnowledgeItem {
  id: string;
  title: string;
  description: string | null;
  content: string | null;
  type: KnowledgeType;
  url: string | null;
  fileUrl: string | null;
  imageUrl: string | null;
  articleCode: string | null;
}

export async function POST(request: NextRequest) {
  try {
    // Rate limiting by session or IP
    const clientId = request.headers.get("x-session-id") || 
                     request.headers.get("x-forwarded-for") || 
                     "anonymous";
    
    const rateLimit = checkRateLimit(clientId, "chat");
    
    if (!rateLimit.allowed) {
      return NextResponse.json(
        { 
          message: "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ.",
          retryAfter: rateLimit.headers["X-RateLimit-Reset"],
        },
        { 
          status: 429,
          headers: rateLimit.headers,
        }
      );
    }

    // Check queue capacity
    if (!aiQueue.hasCapacity()) {
      const waitTime = aiQueue.getEstimatedWaitTime();
      return NextResponse.json(
        { 
          message: "–°–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.",
          estimatedWait: Math.ceil(waitTime / 1000),
        },
        { status: 503 }
      );
    }

    const body = await request.json();
    const { message, sessionId, chatHistory } = body as {
      message: string;
      sessionId: string;
      chatHistory: ChatMessage[];
    };

    if (!message) {
      return NextResponse.json(
        { message: "message is required" },
        { status: 400 }
      );
    }

    // === OPTIMIZATION 1: Instant responses for greetings ===
    const instantResponse = getInstantResponse(message);
    if (instantResponse) {
      return NextResponse.json({
        content: instantResponse,
        attachments: [],
        cached: true,
        responseTime: 0,
      });
    }

    // === OPTIMIZATION 2: Check semantic cache for similar questions ===
    const cachedResponse = aiResponseCache.get(message);
    if (cachedResponse) {
      return NextResponse.json({
        content: cachedResponse.response,
        attachments: [],
        cached: true,
        cacheHit: true,
      });
    }

    // === OPTIMIZATION 3: Smart routing ===
    const routingDecision = analyzeQuestion(message);

    // Load AI settings with caching (1 minute TTL)
    const aiSettings = await withCache(
      aiSettingsCache,
      "ai-settings",
      async () => (await getPrisma()).aISettings.findFirst()
    );

    // Prepare LLM settings
    const llmSettings: AIProviderSettings = {
      provider: aiSettings?.provider || "openai",
      apiKey: aiSettings?.apiKey,
      baseUrl: aiSettings?.baseUrl,
      model: aiSettings?.model || "gpt-4o-mini",
      temperature: aiSettings?.temperature || 0.7,
      maxTokens: aiSettings?.maxTokens || 2048,
      systemPrompt: aiSettings?.systemPrompt,
    };

    // Load knowledge base and XML feed in parallel with caching
    const [aiKnowledgeBase, xmlFeedItems] = await Promise.all([
      withCache(
        knowledgeBaseCache,
        "ai-sources",
        async () => (await getPrisma()).knowledgeBase.findMany({ where: { isAiSource: true } })
      ),
      withCache(
        knowledgeBaseCache,
        "xml-feeds",
        async () => (await getPrisma()).knowledgeBase.findMany({ where: { type: "XML_FEED" } })
      ),
    ]);

    // Build product index
    const productIndex = new Map<string, Product[]>();
    for (const item of xmlFeedItems) {
      const xmlData = item.xmlData as { products?: Product[] } | null;
      if (xmlData?.products) {
        for (const product of xmlData.products) {
          if (product.vendorCode) {
            const code = String(product.vendorCode).toLowerCase();
            if (!productIndex.has(code)) productIndex.set(code, []);
            productIndex.get(code)!.push(product);
          }
        }
      }
    }

    // === ARTICLE LOOKUP LOGIC ===
    const articleCode = extractArticleCode(message);
    const hasKnowledgeKeywords = isKnowledgeBaseRequest(message);

    if (articleCode && productIndex.size > 0) {
      const normalizedCode = articleCode.toLowerCase();
      
      // === CHECK ARTICLE CACHE FIRST ===
      if (!hasKnowledgeKeywords) {
        const cachedArticle = getCachedArticleResponse(normalizedCode);
        if (cachedArticle) {
          return NextResponse.json({
            content: cachedArticle.content,
            attachments: cachedArticle.attachments,
            cached: true,
            articleCache: true,
          });
        }
      }
      
      const matchedProducts = productIndex.get(normalizedCode) || [];

      // === EXACT MATCH FOUND ===
      if (matchedProducts.length > 0 && !hasKnowledgeKeywords) {
        const product = matchedProducts[0];

        // Return product info as JSON payload
        const productInfoPayload = {
          type: "product_info",
          data: {
            name: product.name,
            vendorCode: product.vendorCode,
            description: product.description,
            picture: product.picture,
            price: product.price ? `${product.price}` : "–Ω–µ —É–∫–∞–∑–∞–Ω–∞",
            params: product.params || {},
          },
        };

        const aiAttachments = product.picture
          ? [{ name: product.name, url: product.picture, type: "image" }]
          : [];

        const responseContent = JSON.stringify(productInfoPayload);
        
        // Cache the article response
        cacheArticleResponse(normalizedCode, responseContent, aiAttachments);

        return NextResponse.json({
          content: responseContent,
          attachments: aiAttachments,
        });
      }

      // === SIMILAR ARTICLES SEARCH ===
      if (!hasKnowledgeKeywords && matchedProducts.length === 0) {
        const similarArticles: Product[] = [];

        // Search by prefix and contains
        productIndex.forEach((products, key) => {
          // Prefix match (e.g., "ABC12" matches "ABC12-1", "ABC12-2")
          if (key.startsWith(normalizedCode) && key !== normalizedCode) {
            similarArticles.push(...products);
          }
          // Contains match (e.g., "123" matches "ABC123")
          else if (key.includes(normalizedCode) && key !== normalizedCode && !key.startsWith(normalizedCode)) {
            similarArticles.push(...products);
          }
        });

        if (similarArticles.length > 0) {
          // Deduplicate by vendor code
          const uniqueArticles = similarArticles.reduce<Product[]>(
            (acc, product) => {
              if (!acc.find((p) => p.vendorCode === product.vendorCode)) {
                acc.push(product);
              }
              return acc;
            },
            []
          );

          // Sort alphabetically and limit to 15
          uniqueArticles.sort((a, b) =>
            String(a.vendorCode).localeCompare(String(b.vendorCode))
          );
          const limitedArticles = uniqueArticles.slice(0, 15);

          const suggestionText = `–¢–æ—á–Ω–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞ **${articleCode.toUpperCase()}** –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n\n${limitedArticles
            .map((p) => `üî∏ **${p.vendorCode}** ‚Äî ${p.name}`)
            .join("\n")}${uniqueArticles.length > 15 ? `\n\n...–∏ –µ—â—ë ${uniqueArticles.length - 15} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤` : ""}\n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ –∞—Ä—Ç–∏–∫—É–ª –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç.`;

          return NextResponse.json({
            content: suggestionText,
            attachments: [],
          });
        } else {
          // No similar articles found
          return NextResponse.json({
            content: `–ò–∑–≤–∏–Ω–∏—Ç–µ, –∞—Ä—Ç–∏–∫—É–ª **${articleCode.toUpperCase()}** –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–≤–µ—Å—Ç–∏ —á–∞—Å—Ç—å –∞—Ä—Ç–∏–∫—É–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞.`,
            attachments: [],
          });
        }
      }
      
      // === KNOWLEDGE BASE REQUEST FOR SPECIFIC ARTICLE ===
      if (hasKnowledgeKeywords && matchedProducts.length > 0) {
        // Continue to knowledge base logic below with article context
        const product = matchedProducts[0];
        // Add product context to the knowledge base search
        const productContext = `\n\n–ü—Ä–æ–¥—É–∫—Ç –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É ${product.vendorCode}: ${product.name}`;
        // This will be used in knowledge base search
      }
    }

    // === GENERAL KNOWLEDGE BASE LOGIC ===
    const knowledgeItems = aiKnowledgeBase.filter(
      (item) => item.type !== "XML_FEED"
    );
    let relevantItems: KnowledgeItem[] = [];

    if (knowledgeItems.length > 0) {
      const itemListForLLM = knowledgeItems.map((item) => ({
        title: item.title,
        description: item.description,
        article_code: item.articleCode,
      }));

      // Use LLM to find relevant items
      const searchPrompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "${message}".
–ù–∞–π–¥–∏ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞:
${JSON.stringify(itemListForLLM, null, 2)}
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏—è (title) —Å–∞–º—ã—Ö –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤.`;

      const searchResult = (await invokeLLM({
        prompt: searchPrompt,
        responseJsonSchema: {
          type: "object",
          properties: {
            relevant_titles: {
              type: "array",
              items: { type: "string" },
            },
          },
          required: ["relevant_titles"],
        },
        settings: llmSettings,
      })) as { relevant_titles?: string[] };

      if (searchResult?.relevant_titles?.length) {
        relevantItems = knowledgeItems.filter((item) =>
          searchResult.relevant_titles!.includes(item.title)
        );

        // Apply keyword filters
        const messageLower = message.toLowerCase();
        if (messageLower.includes("–ª–æ–≥–æ—Ç–∏–ø")) {
          relevantItems = relevantItems.filter((i) =>
            i.title.toLowerCase().includes("–ª–æ–≥–æ—Ç–∏–ø")
          );
        } else if (messageLower.includes("–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü")) {
          relevantItems = relevantItems.filter((i) =>
            i.title.toLowerCase().includes("–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü")
          );
        } else if (messageLower.includes("–∫–∞—Ç–∞–ª–æ–≥")) {
          relevantItems = relevantItems.filter((i) =>
            i.title.toLowerCase().includes("–∫–∞—Ç–∞–ª–æ–≥")
          );
        } else if (messageLower.includes("—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç")) {
          relevantItems = relevantItems.filter((i) =>
            i.title.toLowerCase().includes("—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç")
          );
        } else if (messageLower.includes("–±—Ä–µ–Ω–¥–±—É–∫")) {
          relevantItems = relevantItems.filter((i) =>
            i.title.toLowerCase().includes("–±—Ä–µ–Ω–¥–±—É–∫")
          );
        }
      }
    }

    // Check for download-type items (yandex_disk)
    if (relevantItems.length > 0) {
      const yandexDiskItems = relevantItems.filter(
        (i) => i.type === "YANDEX_DISK"
      );
      const downloadKeywords = [
        "—Å–∫–∞—á–∞—Ç—å",
        "–¥–æ–∫—É–º–µ–Ω—Ç",
        "—Ñ–∞–π–ª",
        "–ª–æ–≥–æ",
        "–∫–∞—Ç–∞–ª–æ–≥",
        "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç",
        "–±—Ä–µ–Ω–¥–±—É–∫",
        "–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü",
      ];
      const isDirectDownloadRequest = downloadKeywords.some((kw) =>
        message.toLowerCase().includes(kw)
      );
      const allRelevantAreYandexDisk = relevantItems.every(
        (i) => i.type === "YANDEX_DISK"
      );
      const shouldShowAsCards =
        isDirectDownloadRequest ||
        (allRelevantAreYandexDisk &&
          yandexDiskItems.length > 0 &&
          yandexDiskItems.length <= 3);

      if (yandexDiskItems.length > 1 && shouldShowAsCards) {
        // Return multi download links
        const multiDownloadPayload = {
          type: "multi_download_links",
          data: {
            items: yandexDiskItems.map((item) => ({
              text: `–°–∫–∞—á–∞—Ç—å "${item.title}"`,
              url: item.url,
              title: item.title,
            })),
          },
        };
        return NextResponse.json({
          content: JSON.stringify(multiDownloadPayload),
          attachments: [],
        });
      }

      if (yandexDiskItems.length === 1 && shouldShowAsCards) {
        // Return single download link
        const item = yandexDiskItems[0];
        const downloadPayload = {
          type: "download_link",
          data: {
            text: `–í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å "${item.title}" –ø–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Å—ã–ª–∫–µ`,
            url: item.url,
          },
        };
        return NextResponse.json({
          content: JSON.stringify(downloadPayload),
          attachments: [],
        });
      }

      // Use LLM with context
      let knowledgeContext = relevantItems
        .map((item) => {
          let ctx = `–ò—Å—Ç–æ—á–Ω–∏–∫: ${item.title}\n–û–ø–∏—Å–∞–Ω–∏–µ: ${item.description || ""}\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ: ${item.content || ""}`;
          if (item.url) ctx += `\n–°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ—Å—É—Ä—Å: ${item.url}`;
          if (item.fileUrl) ctx += `\n–°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª: ${item.fileUrl}`;
          return ctx;
        })
        .join("\n\n---\n\n");

      const systemPrompt = `${aiSettings?.systemPrompt || "–í—ã - –ø–æ–ª–µ–∑–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."}

–¢–≤–æ—è –≥–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.

–ü–†–ê–í–ò–õ–ê –û–¢–í–ï–¢–ê:
1. –û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
2. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –µ—Å—Ç—å "–°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ—Å—É—Ä—Å" –∏–ª–∏ "–°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª", —Ç—ã –û–ë–Ø–ó–ê–ù –≤–∫–ª—é—á–∏—Ç—å —ç—Ç—É —Å—Å—ã–ª–∫—É –≤ —Å–≤–æ–π –æ—Ç–≤–µ—Ç. –§–æ—Ä–º–∞—Ç–∏—Ä—É–π —Å—Å—ã–ª–∫–∏ –∫–∞–∫ –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä: [–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Å—ã–ª–∫–∏](URL).
3. –ï—Å–ª–∏ —Å—Å—ã–ª–æ–∫ –Ω–µ—Å–∫–æ–ª—å–∫–æ, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∏—Ö –≤—Å–µ.
4. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º.`;

      const prompt = `–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n${knowledgeContext}\n\n–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞:\n${chatHistory
        .slice(-5)
        .map((msg) => `${msg.role}: ${msg.content}`)
        .join("\n")}\n\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ${message}`;

      const textResponse = await invokeLLM({
        prompt,
        systemPrompt,
        settings: llmSettings,
      });

      const aiAttachments = relevantItems
        .filter((i) => i.imageUrl)
        .map((i) => ({ name: i.title, url: i.imageUrl!, type: "image" }));

      return NextResponse.json({
        content: textResponse as string,
        attachments: aiAttachments,
      });
    }

    // === FALLBACK: No relevant items found ===
    const clarificationPrompt = `–Ø –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "${message}".
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –∏ —Å–ø–∏—Å–æ–∫ —Ç–µ–º, –∫–æ—Ç–æ—Ä—ã–µ —è –∑–Ω–∞—é:
${JSON.stringify(knowledgeItems.map((i) => i.title))}

–°—Ñ–æ—Ä–º–∏—Ä—É–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å. –ü—Ä–µ–¥–ª–æ–∂–∏ 3-4 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Ç–µ–º—ã –∏–∑ —Å–ø–∏—Å–∫–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
–ù–∞–ø—Ä–∏–º–µ—Ä: "–Ø –Ω–µ —Å–æ–≤—Å–µ–º —É–≤–µ—Ä–µ–Ω, —á—Ç–æ –≤—ã –∏—â–µ—Ç–µ. –í–æ–∑–º–æ–∂–Ω–æ, –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç —á—Ç–æ-—Ç–æ –∏–∑ —ç—Ç–æ–≥–æ: ...?"`;

    const clarificationResponse = await invokeLLM({
      prompt: clarificationPrompt,
      settings: llmSettings,
    });

    return NextResponse.json({
      content: clarificationResponse as string,
      attachments: [],
    });
  } catch (error) {
    console.error("Error in chat endpoint:", error);
    return NextResponse.json(
      { message: "Internal server error" },
      { status: 500 }
    );
  }
}
